---
title: "AM01 Final Project Group 4"
author: "Study Group 4 - Harsh Tripathi, Nikolaos Panayotou, Wei Guo, Xenia Huber, Xinyue Zhang"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---

```{r, setup, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, echo=FALSE}
library(googlesheets4)
library(tidyverse)
library(janitor) 
library(skimr)
library(countrycode) # to clean up country names
library(broom)
library(car)
library(ggfortify)
library(stringr)
library(mosaic)
library(ggthemes)
library(GGally)
library(readxl)
library(here)
library(tidyquant)
library(infer)
library(openintro)
```


```{r load_data}

#read local copy
ask_a_manager_2021 <- read_csv(here::here("data", "ask_a_manager_2021.csv")) %>% 
  janitor::clean_names()
  
#skim the data
skimr::skim(ask_a_manager_2021)
```


## DATA CLEANING

```{r, data_cleaning}
#data cleaning


ask_a_manager_2021_new <- ask_a_manager_2021 %>% 
  #rename long columns
  rename(age=how_old_are_you,overall_experience=overall_years_of_professional_experience,
         field_experience=years_of_experience_in_field,education_level=highest_level_of_education_completed) %>% 
  #remove certain columns
  select(-timestamp,
         -additional_context_on_job_title ,
         -additional_context_on_income,
         -other_monetary_comp,
         -currency_other) %>% 
  #mutate ordered factors
  mutate(age=factor(age,
                    levels=c("under 18","18-24","25-34","35-44","45-54","55-64","65 or over"),
                    labels =c("under 18","18-24","25-34","35-44","45-54","55-64","65 or over") ,
                    ordered = TRUE),
         
         overall_experience=factor(overall_experience,
                                   levels=c("1 year or less","2 - 4 years","5-7 years","8 - 10 years","11 - 20 years","21 - 30 years","31 - 40 years","41 years or more"),
                                   labels =c("less than 1 year","2-4 years","5-7 years","8-10 years","11-20 years","21-30 years","31-40 years","41 years or more") ,ordered = TRUE),
         
         field_experience=factor(field_experience,
                                 levels=c("1 year or less","2 - 4 years","5-7 years","8 - 10 years","11 - 20 years","21 - 30 years","31 - 40 years","41 years or more"),
                                 labels =c("less than 1 year","2-4 years","5-7 years","8-10 years","11-20 years","21-30 years","31-40 years","41 years or more") ,
                                 ordered = TRUE),
         education_level=factor(education_level,levels=c("High School","Some college","College degree","Master's degree","PhD","Professional degree (MD, JD, etc.)"),
                                labels =c("High School","Some college","College degree",
                                          "Master's degree","PhD","Professional degree"),
                                ordered = TRUE),
         gender=case_when(
           gender=="Other or prefer not to answer"|gender=="Prefer not to answer"|is.na(gender)~"Don't know or NA",
           TRUE~gender),state=ifelse(str_detect(state,",")|is.na(state),"NA",state))

#sort out country

# First we need to convert country name to iso3c
ask_a_manager_2021_new$iso3c <-countrycode(
  ask_a_manager_2021_new$country,
  origin = "country.name", destination = "iso3c")
# then change it back to country name
ask_a_manager_2021_new$country <-countrycode(
  ask_a_manager_2021_new$iso3c,
  origin = "iso3c", destination = "country.name")

#create a list of industries with more than 100 respondents
industry_list<-ask_a_manager_2021_new %>% 
        group_by(industry) %>% 
        count(sort=TRUE) %>% 
        filter(n > 100) %>% 
        select(industry) %>% pull()
#filter datafame so that it includes only those industries
ask_a_manager_2021_new<-ask_a_manager_2021_new %>% 
     filter(industry %in% industry_list)

#create a list of races with more than 100 respondents
race_list<-ask_a_manager_2021_new %>% 
  group_by(race) %>% 
  count(sort=TRUE) %>% 
  filter(!is.na(race),n>100) %>% 
  select(race) %>% pull()
ask_a_manager_2021_new<-ask_a_manager_2021_new %>% 
  filter(race %in% race_list)

```

```{r}
skim(ask_a_manager_2021_new)
```

```{r cleaned_data}
#drop_na
ask_a_manager_2021_cleaned<-
  ask_a_manager_2021_new %>%  drop_na()

#filter
ask_a_manager_2021_cleaned<-
  ask_a_manager_2021_cleaned %>% 
  filter(annual_salary>10000&annual_salary<1000000)

skim(ask_a_manager_2021_cleaned)
```
```{r, countries with the most respondents }
#we will filter for countries with the most respondents
ask_a_manager_2021_cleaned %>% 
  count(country, sort=TRUE) %>% 
  top_n(10) %>% 
#plot the counts of each country
  ggplot(aes(x=fct_reorder(country,n,.desc=TRUE),y= n,fill=country))+
  geom_col(fill= "slateblue1")+
  theme_bw()+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  labs(y="Count", 
       x="Country")+
  guides(fill=FALSE)+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))+
  NULL
# use countrycode::countryname() to clean country names
```

```{r, include only us data}
#delete country and rename country value as iso3, filter USA
us_data <-
  ask_a_manager_2021_cleaned %>% 
  select(-country) %>% 
  filter(iso3c== "USA")

us_data <- us_data %>%
  mutate(
    log_salary = log(annual_salary)
    ) %>% 
  drop_na()
```


## EXPLORATORY DATA ANALYSIS

```{r, salary distribution}

# How is salary distributed?
ggplot(us_data, aes(y=annual_salary))+
  geom_boxplot()+
 labs(y="Annual Salary", 
       x="",
       title="Boxplot of Annual Salary")+
  theme_bw()+
   theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

ggplot(us_data, aes(x=annual_salary))+
  stat_ecdf()+
   labs(y="ECDF value", 
       x="Annual Salary ($)",
       title="ECDF plot of Annual Salary")+
  theme_bw()
```


```{r, log salary distribution}

# what about log(salary)? 
ggplot(us_data, aes(x=log(annual_salary)))+
  geom_density()+
  labs(y="Density", 
       x="Log of Annual Salary",
       title="Density plot of log(Annual Salary)")+
  theme_bw()


ggplot(us_data, aes(x=log(annual_salary)))+
  stat_ecdf()+
  labs(y="ECDF value", 
       x="Log of Annual Salary",
       title="ECDF plot of log(Annual Salary)")+
  theme_bw()

# Which one (salary vs. log(salary)) is better to use in a regression model? Why?
#log salary appears to b more evenly distributed.
```



```{r, age distribution }
# age distribution in the survey

us_data %>% 
  count(age) %>% 
  ggplot(aes(x=age,y=n,fill=age)) +
  geom_col()+
  labs(x="Age group", 
       y="Count")+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  theme_bw()+
  scale_fill_brewer(palette = "Blues")+
  guides(fill=FALSE)


```


```{r, most observed industries }
# More than 1000 industries can be observed in our dtaframe
#we will filter for industries with more than 500 respondents

us_data %>% 
  count(industry, sort=TRUE) %>% 
  mutate(percent = 100* n/sum(n)) %>% 
  filter(n>=500) %>% 
  ggplot(aes(x=fct_reorder(industry,n,.desc = TRUE),y= n,fill=industry))+
  geom_col(fill= "slateblue1")+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
    labs(x="Industry", 
       y="Count",
       title="Industries with >500 repondents")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))+
  guides(fill=FALSE)
```



```{r, city barchart }
# 'city' 
us_data %>% 
  count(city, sort=TRUE) %>% 
  # mutate(percent = 100* n/sum(n)) %>% 
  top_n(15) %>% 
  ggplot(aes(x=fct_reorder(city,n, .desc=TRUE),y= n))+
  geom_col(fill= "slateblue1")+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  theme_bw()+
  labs(title="Frequencies of Cities",
       y="Count", 
       x="City")+
   guides(fill=FALSE)+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))+
  NULL
```


```{r, education level bar chart }
# education
us_data %>% 
  filter(!is.na(education_level)) %>% 
  count(education_level) %>% 
  ggplot(aes(x=education_level,y= n,fill=education_level))+
  geom_col()+
  theme_bw()+
  labs(title= "Frequency of each educational level",
       x= "Education level",
       y="Count")+
  scale_fill_brewer(palette = "Blues")+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  guides(fill=FALSE)+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

```



```{r, race variable manipulation}

#Cleaning the race variable(white was included with other races)
us_data <- us_data %>% 
  mutate(
    race_cleaned = case_when(
      race %in% c('Asian or Asian American', 'Asian or Asian American, White') ~ 'Asian or Asian American',
      race %in% c('Black or African American', 'Black or African American, White') ~ 'Black or African American',
      race %in% c('Hispanic, Latino, or Spanish origin', 'Hispanic, Latino, or Spanish origin, White') ~ 'Hispanic, Latino, or Spanish origin',
      race == "Another option not listed here or prefer not to answer" ~ "Others/Prefer not to say",
      TRUE ~ race
    )
  )
skim(us_data$race_cleaned)
```


```{r, plot the race frequencies }
# race
us_data %>% 
  filter(!is.na(race_cleaned)) %>% 
  count(race_cleaned) %>% 
  ggplot(aes(x=fct_reorder(race_cleaned,n,.desc=TRUE),y= n,fill=race_cleaned))+
  geom_col(fill= "slateblue1")+
  theme_bw()+
  labs(title="Race Frequency",
       x= "Race",
       y="Count")+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  guides(fill=FALSE)+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

```


```{r, barchart for proffesional experience years }

# overall_years_of_professional_experience 
us_data %>% 
  count(overall_experience ) %>% 
  ggplot(aes(x=overall_experience,y = n))+
  geom_col(fill= "slateblue1")+
  labs(x="Years of Professional Experience", 
       y="Count",
       title="Years of Experience Frequency")+
  theme_bw()+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

```


```{r, barchart for years of professional experience in particular field }
# years_of_experience_in_field  
us_data %>% 
  count(field_experience) %>% 
  ggplot(aes(x=field_experience,y = n))+
  geom_col(fill= "slateblue1")+
   labs(x="Years of Experience in Particular Field", 
       y="Count",
       title="Frequency of Field Experience")+
  theme_bw()+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

```


```{r, observe the frequencies of each gender}
# gender
us_data %>% 
  count(gender) %>% 
  ggplot(aes(x=fct_reorder(gender,n,.desc=TRUE),y = n,fill=gender))+
  geom_col(fill= "slateblue1")+
  theme_bw()+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  guides(fill=FALSE)+
  labs(title= "Frequency of each gender",
       x="Gender",
       y="Count")+
  NULL
```
```{r,compare salaries for each gender}

#create table
us_data %>% 
  group_by(gender) %>% 
  summarize(
    mean_salary = mean(annual_salary)
  ) %>% 
#plot barchart  
  ggplot(aes(x = reorder(gender, -mean_salary), y = mean_salary)) +
  geom_col(fill= "slateblue1")+
 geom_text(aes(label=round(mean_salary,0)),size=3,vjust=-0.25)+
   labs(x="Gender", 
       y="Average Salary",
       title="Average Salary for Gender (US)")+
  theme_bw()
```


```{r, facet wrap for women and men}

us_data %>% 
  group_by(gender) %>% 
  count(industry, sort=TRUE) %>% 
  mutate(percent = 100* n/sum(n)) %>% 
  filter(n>=500) %>% 
  ggplot(aes(y=fct_reorder(industry,n,.desc = TRUE),x= n,fill=industry))+
  geom_col()+
  geom_text(aes(label=n),size=3,vjust=-0.25)+
  facet_wrap(~gender)+
    labs(x="Count",
         y="Industry",
         title="Industries with >500 repondents",
         subtitle="Men only work in the tech industy for our data")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))+
  guides(fill=FALSE)
```


Null Hypothesis $H_0$ : $\mu_{Men.tech.salary} - \mu_{Female.tech.salary} = 0$

Alternative Hypothesis $H_1$ : $\mu_{Men.tech.salary} - \mu_{Female.tech.salary}\neq 0$
```{r, Salaries in Tech for each gender, height = 0.1}

#compute confidence intervals

us_data_menvswomen <- us_data%>%
  filter(industry == "Computing or Tech") %>% 
  filter(gender %in% c("Man", "Woman")) %>% 
  group_by(gender) %>% 
  summarise(mean_salary = mean(annual_salary),
            median_salary = median(annual_salary),
            sd_salary = sd(annual_salary),
            count = n(),
            # get t-critical value with (n-1) degrees of freedom
            t_critical = qt(0.975, count-1),
            se_salary = sd_salary/sqrt(count),
            margin_of_error = t_critical * se_salary,
            salary_low = mean_salary - margin_of_error,
            salary_high = mean_salary + margin_of_error) %>% 
  arrange(desc(mean_salary))
  us_data_menvswomen
  
 # using welch  t test
us_data_2 <- us_data %>% 
    filter(industry == "Computing or Tech") %>% 
  filter(gender %in% c("Man", "Woman"))


t.test(annual_salary ~ gender , data = us_data_2)

#boxplots
us_data %>% 
  group_by(gender) %>% 
  ggplot(aes(x=gender, y=annual_salary))+
  geom_violin()+
  geom_boxplot(width=0.3)+
  labs(x="Gender", 
       y="Annual Salary",
       title="Annual Salary for Gender (US)")+
  theme_bw()

us_data %>% 
  filter(industry == "Computing or Tech") %>% 
  group_by(gender) %>% 
  ggplot(aes(x=gender, y=annual_salary))+
  geom_violin()+
  geom_boxplot(width=0.3)+
   labs(x="Gender", 
       y="Annual Salary in Tech",
       title="Annual Salary in Tech for Gender (US)")+
  theme_bw()
```

```{r, salaries across USA cities}
#create a table with mean salaries across different US cities
us_data %>% 
  group_by(city) %>% 
  summarise(mean_salary = mean(annual_salary),
            count = n()
         ) %>% 
  arrange(desc(mean_salary)) %>% 
  #display only top 15
 top_n(15) 
```
Null Hypothesis $H_0$ : $p_{SF.tech} = p_{notSF.tech} $

Alternative Hypothesis $H_1$ : $p_{SF.tech} \neq p_{notSF.tech} $
```{r, SF hypothesis}

#we will examine if San Francisco holds a bigger proportion of tech employees than other cities


#find % of tech employees in SF
us_data %>% 
  filter(city == "San Francisco") %>% 
  count(industry) %>% 
  mutate(percent = n/sum(n)*100,
         total = sum(n)) %>%  
  arrange(desc(n))
#find % of tech employees in US excluding SF  
us_data %>% 
  filter(city != "San Francisco") %>% 
  count(industry) %>% 
  mutate(percent = n/sum(n)*100,
         total = sum(n)) %>% 
  arrange(desc(n))


#two proportion z test
tech<- c(243, 3174)
totals <- c(504, 18990)

res1 <- prop.test(x = tech, n = totals)
res1

```


```{r, race in tech}
#plot race in tech industry


us_data %>% 
  filter(industry == "Computing or Tech", race_cleaned != "Others/Prefer not to say") %>%
  group_by(race_cleaned) %>% 
  summarize(
   count = n()
   ) %>% 
  
  ggplot(aes(x = reorder(race_cleaned, -count), y = count)) +
  geom_col(fill= "slateblue1") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
   labs(x="Race", 
       y="Frequency",
       title="Frequency of each race in Tech")+
  theme_bw()+
  geom_text(aes(label=count),size=3,vjust=-0.25)+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))



```

Null Hypothesis $H_0$ : $p_{Asian.tech} = p_{other.tech} $

Alternative Hypothesis $H_1$ : $p_{Asian.tech} \neq p_{other.tech} $

```{r, proportion of asians in tech vs in other idustries}

#calculate proportions

us_data%>%
  mutate(tech_or_not = case_when(industry == "Computing or Tech"& race_cleaned=="Asian or Asian American" ~ "asian in tech",
                                 industry != "Computing or Tech"& race_cleaned=="Asian or Asian American" ~ "asian in other industry",
                                 industry == "Computing or Tech"& race_cleaned!="Asian or Asian American" ~ "other in tech",
                                 industry != "Computing or Tech"& race_cleaned!="Asian or Asian American" ~ "other in other industry")
  ) %>% 
  count(tech_or_not) 

#two proportion z test
asians<- c(321, 865)
totals <- c(321+3096, 865 + 15212)

res <- prop.test(x = asians, n = totals)
res


```


```{r,race vs salary}
us_data %>% 
  group_by(race_cleaned) %>% 
  filter (race_cleaned != "Others/Prefer not to say" ) %>% 
  summarize(
    mean_salary = mean(annual_salary)
  ) %>% 
  
  ggplot(aes(x = reorder(race_cleaned, -mean_salary), y = mean_salary)) +
  geom_col(fill= "slateblue1") +
  labs(x="Race", 
       y="Average Salary",
       title="Average salary for every race")+
  theme_bw()+
  geom_text(aes(label=round(mean_salary,0)),size=3,vjust=-0.25)+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))
```
Null Hypothesis $H_0$ : $p_{Asian.Salary} = p_{White.Salary} $

Alternative Hypothesis $H_1$ : $p_{Asian.Salary} \neq p_{White.Salary} $

```{r, t test between salaries for different races}

us_data%>%
  group_by(race_cleaned) %>%
  filter (race_cleaned != "Others/Prefer not to say" ) %>% 
  summarise(mean_salary = mean(annual_salary),
            median_salary = median(annual_salary),
            sd_salary = sd(annual_salary),
            count = n(),
            # get t-critical value with (n-1) degrees of freedom
            t_critical = qt(0.975, count-1),
            se_salary = sd_salary/sqrt(count),
            margin_of_error = t_critical * se_salary,
            salary_low_CI = mean_salary - margin_of_error,
            salary_high_CI = mean_salary + margin_of_error) %>% 
  arrange(desc(mean_salary))

 # using welch  t test
us_data_race <- us_data %>% 
  filter(race_cleaned %in% c("White", "Asian or Asian American"))

t.test(annual_salary ~ race_cleaned , data = us_data_race) 

#SAY THAT ALL CIS OVERALL EXCEPT ASIANS VS EVERYONE ELSE

```


```{r,mean salaries for diferent industries}

top_industries <- us_data %>% 
  group_by(industry) %>% 
  count(sort = TRUE) %>% 
  head(10) %>% 
  select(industry) %>% 
  pull()

us_data %>%
  filter(industry %in% top_industries) %>% 
  group_by(industry) %>% 
  summarize(
    mean_salary = mean(annual_salary)
  ) %>% 
  ggplot(aes(x = reorder(industry, -mean_salary), y = mean_salary)) +
  geom_text(aes(label=round(mean_salary,0)),size=3,vjust=-0.25)+
  geom_col(fill= "slateblue1") +
   labs(x="Industry", 
       y="Average Salary",
       title="Average salary for every industry")+
  theme_bw()+
 theme(axis.text.x = element_text(angle = 45, vjust = 0.5))


us_data %>%
  filter(industry %in% top_industries) %>% 
  group_by(industry) %>% 
  ggplot(aes(x = reorder(industry, -annual_salary), y = annual_salary)) +
  geom_violin() +
  geom_boxplot(width=0.1)+
  labs(x="Industry", 
       y="Average Salary",
       title="Distribution of salary for every industry",
       subtitle="Ordered by mean")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
  NULL
```


```{r,salary vs experience levels}

us_data %>%
  ggplot(aes(x = overall_experience, y = annual_salary, fill=overall_experience)) +
  geom_violin()+
  geom_boxplot(width=0.1)+
  scale_fill_brewer(palette="Blues") + theme_classic()+
   labs(x="Overall Experience", 
       y="Annual Salary",
       title="Annual salary for different experience levels",
       subtitle="Ordered by mean")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
  guides(fill=FALSE)+
  NULL

```



```{r, salary for different experience}
us_data %>%
  
  ggplot(aes(x = field_experience, y = annual_salary, fill=field_experience)) +
  geom_violin()+
  geom_boxplot(width=0.1)+
  scale_fill_brewer(palette="Blues") + theme_classic()+
  labs(x="Field Experience", 
       y="Annual Salary",
       title="Annual salary for different field experience",
       subtitle="Ordered by mean")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))+
  guides(fill=FALSE)+


  NULL
```


```{r, average salary vs age}


us_data %>%
  group_by(age) %>% 
  
  ggplot(aes(x = age, y = annual_salary, fill=age)) +
  geom_violin()+
  scale_fill_brewer(palette="Blues") + theme_classic()+
  geom_boxplot(width=0.1)+
   labs(x="Age", 
       y="Annual Salary",
       title="Distribution of annual salary for age")+
  theme_bw()+
  guides(fill=FALSE)+
  NULL
 

```


```{r, education vs salary}

us_data %>%
  ggplot(aes(x = education_level, y = annual_salary,fill=education_level)) +
  geom_violin() +
  scale_fill_brewer(palette="Blues") + theme_classic()+
  geom_boxplot(width=0.1)+
  #geom_text(aes(label=round(mean(annual_salary),0)),size=3,vjust=-0.25)+
  labs(x="Education Level", 
       y="Annual Salary",
       title="Annual salary for different education levels",
       subtitle="mean increases across the plot")+
  theme_bw()+
  guides(fill=FALSE)+
  NULL

```




## REGRESSION MODELING

Since almost all the explanatory variables are categorical, we try merging some of the categories of categorical variables, based on the count of people and mean salary in each category.

#HOW DID WE PICK FIELD EXP OUT OF AGE, FIELD EXPERIENCE AND OVERALL EXPERIENCE!

On running individual models, field_experience is giving highest R^squared. Intuitively, makes sense.


```{r, salary_by_field_exp}
#Count of people and average salary by field_experience
us_data %>%
  group_by(field_experience) %>% 
  
  summarize(
    #Count of people in each category
    count = n(),
    
    #Mean salary in each category
    mean_salary = mean(annual_salary)
  )
```


```{r, manipulating_field_exp}
#Based on count of people and mean salary in each category, merging categories
us_data <- us_data %>% 
  mutate( 
    #Converting the variable to character data type
    field_exp_character = as.character(field_experience), 
    
    #Merging categories
    field_exp_grouped = case_when(
    field_exp_character %in% c("less than 1 year", "2-4 years") ~ "less than 4 years",
    field_exp_character %in% c("21-30 years", "31-40 years", "41 years or more") ~ "21 years or more",
    TRUE ~ field_exp_character
  )
  )

#Checking the new distribution based on field_experience
us_data %>%
  group_by(field_exp_grouped) %>% 
  summarize(
    count = n(),
    mean_salary = mean(annual_salary)
  )
```

```{r, salary_by_field_exp}
#Count of people and average salary by education
us_data %>%
  group_by(education_level) %>% 
  
  summarize(
    #Count of people in each category
    count = n(),
    
    #Mean salary in each category
    mean_salary = mean(annual_salary)
  )
```


```{r, manipulating_education_level}
#Based on count of people and mean salary in each category, merging categories
us_data <- us_data %>% 
  mutate( 
    #Converting the variable to character data type
    edu_level_char = as.character(education_level),
    
    #Merging categories
    edu_level_grouped = case_when(
    edu_level_char %in% c("High School", "Some college") ~ "High School/College",
    TRUE ~ edu_level_char)
  )

#Checking the new distribution based on education_level
us_data %>%
  group_by(edu_level_grouped) %>% 
  summarize(
    count = n(),
    mean_salary = mean(annual_salary)
  )

```


```{r, salary_by_industry}
industry_list <- us_data %>%
  group_by(industry) %>% 
  summarize(
    #Count of people in each category
    count = n(),
    
    #Mean salary in each category
    mean_salary = mean(annual_salary)
  ) %>% 
  arrange(desc(count))

#Considering only those industries which have at least 500 entries
industry_list <- industry_list %>% 
  filter(count > 500) %>% 
  select(industry) %>% 
  pull()
```


```{r, manipulating_industry}
#Based on count of people and mean salary in each category, merging categories
us_data <- us_data %>% 
  mutate( 
    #Merging categories
    industry_grouped = case_when(
    industry %in% c("Education (Higher Education)", "Education (Primary/Secondary)") ~ "Education",
    industry %in% industry_list ~ industry,
    TRUE ~ "Others"
  )
  )

#Checking the new distribution based on industry
us_data %>%
  group_by(industry_grouped) %>% 
  summarize(
    count = n(),
    mean_salary = mean(annual_salary)
  )
```



```{r, salary_by_state}
state_salary <- us_data %>%
  group_by(state) %>% 
  summarize(
    #Count of people in each category
    count = n(),
    
    #Mean salary in each category
    mean_salary = mean(annual_salary)
  ) %>% 
  arrange(desc(mean_salary))

state_salary
```


```{r, states_list_based_on_salary}
#Based on count of people and mean salary in each category, categorising lists based on mean salaries

high_paying_state <- state_salary %>% 
  filter(mean_salary >= 100000) %>% 
  select(state) %>% 
  pull()

moderate_paying_state <- state_salary %>% 
  filter(mean_salary < 100000, mean_salary >= 80000) %>% 
  select(state) %>% 
  pull()

low_paying_state <- state_salary %>% 
  filter(mean_salary < 80000) %>% 
  select(state) %>% 
  pull()
```


```{r, manipulating_states}
#Assigning state category to each row
us_data <- us_data %>% 
  mutate( 
    state_grouped = case_when(
    state %in% high_paying_state ~ "high_paying_state",
    state %in% moderate_paying_state ~ "moderate_paying_state",
    state %in% low_paying_state ~ "low_paying_state")
  )

#Checking the distrubution based on grouped state
us_data %>%
  group_by(state_grouped) %>% 
  summarize(
    count = n(),
    mean_salary = mean(annual_salary)
  )
```


Before training our model, we divide the data into train and test sets in the proportion of 75:25 respectively. We will train our model on the train sets, use the model to get the predictions on the test set and analyze the error of predictions as compared to the actual values.


```{r, train_test_split}
#Splitting the data into train and test sets

library(rsample) #Package to split data
set.seed(1234)

#Keeping 75% data in the training set
train_test_split <- initial_split(us_data, prop = 0.75)

train_data <- training(train_test_split)
test_data <- testing(train_test_split)
```

In the first iteration of the model, we use only field experience as the explanatory variable. As mentioned above, we have merged some categories of the field_experience variable on the basis of count and mean salary in each category to form a field_exp_grouped.


```{r, model1}
#Linear regression model 
model1 <- lm(log_salary ~ field_exp_grouped, data = train_data)

#Summary of the model
mosaic::msummary(model1)

#RMSE on the training set
rmse_train <- train_data %>% 
  mutate(predictions = predict(model1, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on training set is: ", round(rmse_train, 12)))

#RMSE on the testing set
rmse_test <- test_data %>% 
  mutate(predictions = predict(model1, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on testing set is: ", round(rmse_test, 4)))
```

We observe that all the variables are significant at 95% confidence level as the p-value is less than 0.05. We get an R^2 of 11% and the test RMSE is 0.2047. Now, we add "race" to our model.


```{r, model2}
#Linear regression model
model2 <- lm(log_salary ~ field_exp_grouped + race_cleaned, data = train_data)

#Summary of the model
mosaic::msummary(model2)

#RMSE on the training set
rmse_train <- train_data %>% 
  mutate(predictions = predict(model2, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on training set is: ", round(rmse_train, 12)))

#RMSE on the testing set
rmse_test <- test_data %>% 
  mutate(predictions = predict(model2, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on testing set is: ", round(rmse_test, 4)))
```
On using race as an explanatory variable in addition to age, we see that all the variables are still signficant at 95% confidence level. The R^2 increases to 12% and the test RMSE in 0.19.

Now, we add gender to our model.


```{r, model3}
#Linear regression model 
model3 <- lm(log_salary ~ field_exp_grouped + race_cleaned + gender, data = train_data)

#Summary of the model
mosaic::msummary(model3)

#RMSE on the training set
rmse_train <- train_data %>% 
  mutate(predictions = predict(model3, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on training set is: ", round(rmse_train, 12)))

#RMSE on the testing set
rmse_test <- test_data %>% 
  mutate(predictions = predict(model3, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on testing set is: ", round(rmse_test, 4)))
```

On adding gender to our model, we observe that all variables of field_exp and race are significant. Out of 3 gender variables, 2 are significant at 95% confidence level. The R^2 increases to 16% and the test RMSE is 0.18.

Now, we add education level to our model.

```{r, model4}
#Linear regression model 
model4 <- lm(log_salary ~ field_exp_grouped + race_cleaned + gender + edu_level_grouped, data = train_data)

#Summary of the model
mosaic::msummary(model4)

#RMSE on the training set
rmse_train <- train_data %>% 
  mutate(predictions = predict(model4, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on training set is: ", round(rmse_train, 12)))

#RMSE on the testing set
rmse_test <- test_data %>% 
  mutate(predictions = predict(model4, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on testing set is: ", round(rmse_test, 4)))
```
We observe that all education_level variables are significant. The R^squared increases to 22% and the test RMSE is 0.22. We notice that the test RMSE increases to 0.22 from 0.18, which could mean that the model is beginning to become overfitting.


We now add industry to our model -



```{r, model5}
#Linear regression model 
model5 <- lm(log_salary ~ field_exp_grouped + race_cleaned + gender + edu_level_grouped + industry_grouped, data = train_data)

#Summary of the model
mosaic::msummary(model5)

#RMSE on the training set
rmse_train <- train_data %>% 
  mutate(predictions = predict(model5, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on training set is: ", round(rmse_train, 12)))

#RMSE on the testing set
rmse_test <- test_data %>% 
  mutate(predictions = predict(model5, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on testing set is: ", round(rmse_test, 4)))
```

We observe that most of the industry variables are significant at 95% confidence level. The R^squared increases to 38% and the test RMSE drops significantly to 0.06.


Lastly, we add state to our model -


```{r, model6}
#Linear regression model 
model6 <- lm(log_salary ~ field_exp_grouped + race_cleaned + gender + edu_level_grouped + industry_grouped + state_grouped, data = train_data)

#Summary of the model
mosaic::msummary(model6)

#RMSE on the training set
rmse_train <- train_data %>% 
  mutate(predictions = predict(model6, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on training set is: ", round(rmse_train, 12)))

#RMSE on the testing set
rmse_test <- test_data %>% 
  mutate(predictions = predict(model6, .)) %>% 
  summarise(
    sqrt(sum(predictions - log_salary)**2 / n())
  ) %>% 
  pull()

cat(paste0("\nRMSE on testing set is: ", round(rmse_test, 4)))
```

We see that all variables of state are independent. The R^2 increases to 44% and the test RMSE is 0.1068.

We now check for collinearity between explanatory variables in our model by calculating VIF - 

```{r, vif}
#Calculating the variance inflation factor to check collinearity
car::vif(model6)
```

On calculating the Variance Inflation Factor (VIF) for the model, we observe that the values are not very high, which means that we do not have a problem of high multi-collinearity in our model.

We now do residual analysis for our model -


```{r, residual_analysis, fig.width = 10}
library(ggfortify) #Package for residual analysis

#Plotting graphs for residual analysis
autoplot(model6, which = 1:2) +
  #Using black and white theme
  theme_bw()
```

By performing Residual Analysis, we observe that there is no significant pattern in the Residuals vs Fitted values plot. It is close to an ideal plot and we can conclude that there is no evidence of non-linear relationship between X & Y or non-constant variance. There seems to be no significant pattern in the data that is currently unaccounted for.

The Q-Q plot has most of the values on the straight line between -2 and +2. Hence, we can conclude that the residuals follow a Normal Distribution.




